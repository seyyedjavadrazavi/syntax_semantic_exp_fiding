## Syntax and Semantix expert recommendation
This repository contains the code of our paper. To run the code for your dataset, please follow the below instructions:

## Progress
To use this code for your purposes and dataset, follow and run the files in order based on their numbers. Each folder is named with a number to indicate the sequence, from `1_preparation` to `4_MLP`. Within each folder, if order matters, the files follow a similar pattern; otherwise, you can run them in any order. Detailed instructions for each section are provided below.

## 0. Download Dataset
We used the Stack Exchange dataset. You can download it from [archive.org](https://archive.org/details/stackexchange). Download the datasets and then extract each dataset to the data directory, in the corresponding folder. For instance, you should extract the `biology` dataset into the `./data/biology`.

## 1. Preparation
To convert XML files to CSVs, firstly, you should run all the Python files in the `1_prepration` folder. So, you should run the Python files in the `Comments`, `Posts`, `Tags`, `User`, and `Worker` directories. Paths are relative, and all files will be stored in the `data` directory. You may change the name of the directory for each different dataset in the Python codes.

## 2. situation_vector
This folder is responsible for computing the Syntax and Semantic similarities between texts. 

## 2_1 Word2Vec
In the `W2V` folder, we first compute the permutation of tags, to have the all possible sequence of questions' tags, in `1_seprate_tags`, then train and create word2vec vectors in `2_create_word2vec`. We will use the W2V model in computing the semantic similarity.

## 2_2 Syntaxt Similarity
In the `2_tree` folder, we sort the questions' tags separately based on the number of tags, then, compute the Syntax similarity between questions via the `tree`. The questions' tags are considered in the Syntax similarity, tree section. First, the children of a question are found. This means that the questions that at least have the input questions' tag or more number questions' tag are considered as the children of a question. Then, in the case of an inadequate number of candidate questions, siblings of the input question are found. Siblings are the questions that have the same tags with the new question with a different tag. Then, if the number of candidate questions is low, the parent of the input question will be found, which you can read about in the paper.

## 3 Semantic Similarity
## 3_1 Graph
In this section, firstly, one of the input/new question's tags is selected and the five most similar tags with it are computed via the W2V model. Then questions with at least one of these tags are selected. In a recursive loop, again the five most similar tags with the second tag of the new question are considered and among selected questions in the previous step, questions with these tags are selected as new candidates. This approach is continued till all the new question tags are considered or the number of left candidates will be less than required. In each step, to select the new candidates, the Apriori algorithm is used.

## 3_2 Sbert -> 4_sbert_stack_overflow
The next step is  employing the Bert Score to calculate the similarity between the body of questions. To compute this, because of the time-consuming of process, a short list of candidates is generated by getting the average of `tree` and `graph` candidates. The Bert score of candidates with higher scores is calculated. 

## 5 Union
The average of all candidates in the past three phases, `tree`, `graph`, and `bscore`, is computed to finalize the candidates. This is computed via two methods. intersections and Ordering based. In the first method, firstly, we get the intersection of three candidate lists and find the subscription list. These questions, because all the similarity methods recommend them, are selected in the first. Then other questions are selected based on their similarity scores. In the second method, all the questions is ordered and candidates are selected based on their similarity scores. 

## 6 Task Difficulty
